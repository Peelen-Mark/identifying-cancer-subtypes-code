{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "from scipy.linalg import svd\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "mirna_data = pd.read_csv(r'MDICC-data\\BRCA\\original_data\\mirna.csv')\n",
    "gene_data = pd.read_csv(r'MDICC-data\\BRCA\\original_data\\gene.csv')\n",
    "methy_data = pd.read_csv(r'MDICC-data\\BRCA\\original_data\\methyl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        cg00000292\n",
       "1        cg00002426\n",
       "2        cg00003994\n",
       "3        cg00005847\n",
       "4        cg00007981\n",
       "            ...    \n",
       "22528    cg27657249\n",
       "22529    cg27661264\n",
       "22530    cg27662379\n",
       "22531    cg27662877\n",
       "22532    cg27665659\n",
       "Name: Unnamed: 0, Length: 22533, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the first column of each dataset (the feature names)\n",
    "mirna_data.pop(mirna_data.columns[0])\n",
    "gene_data.pop(gene_data.columns[0])\n",
    "methy_data.pop(methy_data.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(values):\n",
    "    # Scale Z-score\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(values.T)\n",
    "\n",
    "    # Power Transformation\n",
    "    transformer = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "    data_transformed = transformer.fit_transform(scaled_data)\n",
    "    \n",
    "    return data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(datasets):\n",
    "    data = []\n",
    "    dataset_names = ['miRNA', 'gene expression', 'methylation']\n",
    "   \n",
    "    for x in datasets:\n",
    "        # Preprocess the data\n",
    "        X = x.to_numpy()\n",
    "        \n",
    "        # Calculate the percentage of zeros in each row\n",
    "        zero_percentage = np.mean(X == 0, axis=1)\n",
    "\n",
    "        # Get the indices of the rows with less than 20% zeros\n",
    "        keep_indices = np.where(zero_percentage < 0.2)[0]\n",
    "\n",
    "        # Remove the rows with 20% or more zeros\n",
    "        X_without_zeros = X[keep_indices, :]\n",
    "        \n",
    "        # Change 0 values to NaN for the KNN imputer\n",
    "        X_without_zeros[X_without_zeros == 0] = np.nan\n",
    "        \n",
    "        # Determine the amount of neighbours\n",
    "        N = round(np.sqrt(x.shape[1]))\n",
    "        \n",
    "        # Start KNN imputer\n",
    "        imputer = KNNImputer(n_neighbors=N+2)\n",
    "        X = imputer.fit_transform(X_without_zeros)\n",
    " \n",
    "        # Scale the data without the missing values\n",
    "        dataset = scaling(X)\n",
    "        \n",
    "        # Perform Bayesian Gaussian Mixture model with the diagonal covariance matrix\n",
    "        bgmm_model = BayesianGaussianMixture(n_components = dataset.shape[0], covariance_type='diag')\n",
    "        bgmm_model.fit(dataset)\n",
    "        \n",
    "        # Get covariances\n",
    "        covariances = bgmm_model.covariances_\n",
    "\n",
    "        # Convert covariances to a NumPy array\n",
    "        covariances = np.array(covariances)\n",
    "\n",
    "        # Calculate the variances for each feature across components\n",
    "        variances = np.var(covariances, axis=0)\n",
    "\n",
    "        # Sort the variances in descending order\n",
    "        sorted_indices = np.argsort(variances)[::-1]\n",
    "        sorted_variances = variances[sorted_indices]\n",
    "\n",
    "        # Calculate the cumulative explained variance\n",
    "        cumulative_variance = np.cumsum(sorted_variances) / np.sum(sorted_variances)\n",
    "\n",
    "        # Determine the optimal number of features based on a threshold for cumulative variance explained\n",
    "        threshold = 0.95\n",
    "        num_features = np.sum(cumulative_variance < threshold) + 1\n",
    "        \n",
    "        # Save the selected features in the variable\n",
    "        selected_features = dataset[:, sorted_indices[:num_features]]\n",
    "\n",
    "        # Add the new dataset to data\n",
    "        data.append(selected_features)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_relation(X, Y):\n",
    "\n",
    "\n",
    "    # Calculate Canonical Correlations by performaing Singular Value Decomposition (SVD)\n",
    "    U, D, V = svd(X.T @ Y)  \n",
    "    \n",
    "    # Get the rank of D (the number of non-zero canonical correlations)\n",
    "    r = np.linalg.matrix_rank(D)\n",
    "\n",
    "    # Select Significant Canonical Correlations\n",
    "    \n",
    "    # Determine the number of canonical correlations to keep\n",
    "    n = min(X.shape[1], Y.shape[1]) \n",
    "    \n",
    "    # Select r significant canonical correlatoins\n",
    "    canonical_correlations = D[:r]  \n",
    "\n",
    "    # Get canonical variates for predictor dataset\n",
    "    Wx = X @ U[:, :r]  \n",
    "    \n",
    "    # Get canonical variates for response dataset\n",
    "    Wy = Y @ V[:, :r]  \n",
    "   \n",
    "    # Compute distance matrix based on the canonical variates\n",
    "    num_samples = len(Wx)\n",
    "    \n",
    "    distances = np.zeros((num_samples, num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        for j in range(i+1, num_samples): \n",
    "            # Compute the Euclidean distance between canonical variates\n",
    "            distance = np.sqrt((Wx[i]-Wx[j])**2 + (Wy[i] - Wy[j])**2)\n",
    "            distances[i, j] = distance\n",
    "            distances[j, i] = distance  \n",
    "    \n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter setting\n",
    "k1 = 18 # the neighbor of affinity matrix\n",
    "k2 = 42 # \n",
    "k3 = 2  # number of cluster\n",
    "c  = 3  # c = k3(c>2) or c = 3(c=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the affinity matrices in the same way as the MDICC paper did,\n",
    "# I would like to refer to the original paper:\n",
    "# Yang, Y., Tian, S., Qiu, Y., Zhao, P., & Zou, Q. (2022). \n",
    "# MDICC: Novel method for multi-omics data integration and cancer \n",
    "# subtype identification. Briefings in Bioinformatics, 23(3), bbac132.\n",
    "\n",
    "def kscale(matrix, k=7, dists=None, minval=0.004):\n",
    "    \"\"\" Returns the local scale based on the k-th nearest neighbour \"\"\"\n",
    "    r,c = matrix.shape\n",
    "    scale = np.zeros((r,c))\n",
    "    for i in range(1,(k+1)):\n",
    "        ix = (np.arange(len(matrix)), matrix.argsort(axis=0)[i])\n",
    "        d = matrix[ix][np.newaxis].T\n",
    "        dists = (d if dists is None else dists)\n",
    "        scale1 = dists.dot(dists.T)\n",
    "        \n",
    "        scale = scale1 + scale\n",
    "    scale = scale/k\n",
    "    return np.clip(scale, minval, np.inf)\n",
    "\n",
    "\n",
    "def affinity(matrix, k):\n",
    "    scale = kscale(matrix, k)\n",
    "    msq = matrix * matrix\n",
    "    scaled = -msq /(0.5*scale+0.5*matrix)\n",
    "    scaled[np.where(np.isnan(scaled))] = 0.0\n",
    "    a = np.exp(scaled)\n",
    "    a.flat[::matrix.shape[0]+1] = 0.0  # zero out the diagonal\n",
    "    return a\n",
    "\n",
    "\n",
    "def testaff(matrix,k):\n",
    "    k = int(k)\n",
    "    a = matrix\n",
    "    affi = affinity(a,k)\n",
    "    return affi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\markp\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "datasets = [mirna_data, gene_data, methy_data]\n",
    "data = get_data(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the affinity matrix for gene expression as predictor dataset and miRNA as response dataset\n",
    "d10 = calc_relation(data[1], data[0])\n",
    "A10 = testaff(d10, k1)\n",
    "pd.DataFrame(asarray(A10)).to_csv(\"A10_BRCA.csv\")\n",
    "\n",
    "# Compute the affinity matrix for miRNA as predictor dataset and gene epxression as response dataset\n",
    "d01 = calc_relation(data[0], data[1])\n",
    "A01 = testaff(d01, k1)\n",
    "pd.DataFrame(asarray(A01)).to_csv(\"A01_BRCA.csv\")\n",
    "\n",
    "# Compute the affinity matrix for gene expression as predictor dataset and methylation as response dataset\n",
    "d12 = calc_relation(data[1], data[2])\n",
    "A12 = testaff(d12, k1)\n",
    "pd.DataFrame(asarray(A12)).to_csv(\"A12_BRCA.csv\")\n",
    "\n",
    "# Compute the affinity matrix for methylation as predictor dataset and gene epxression as response datas\n",
    "d21 = calc_relation(data[2], data[1])\n",
    "A21 = testaff(d21, k1)\n",
    "pd.DataFrame(asarray(A21)).to_csv(\"A21_BRCA.csv\")\n",
    "\n",
    "# Compute the affinity matrix for methylation as predictor dataset and miRNA as response datas\n",
    "d20 = calc_relation(data[2], data[0])\n",
    "A20 = testaff(d20, k1)\n",
    "pd.DataFrame(asarray(A20)).to_csv(\"A20_BRCA.csv\")\n",
    "\n",
    "# Compute the affinity matrix for miRNA as predictor dataset and methylation as response datas\n",
    "d02 = calc_relation(data[0], data[2])\n",
    "A02 = testaff(d02, k1)\n",
    "pd.DataFrame(asarray(A02)).to_csv(\"A02_BRCA.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
